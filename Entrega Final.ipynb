{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Angie Carolina Joya  Duarte - 2322609**\n",
    "\n",
    "**Emily Nuñez Ordoñez - 2240156**\n",
    "\n",
    "**Hassen Ortiz Alvarez - 2177273**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importan las librerías necesarias y se configuran los parámetros de la librería matplotlib para que las gráficas que va a generar sean embebidas en el notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch import nn, optim\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen algunas variables relacionadas con las propiedades del conjunto de datos para ser utilizadas en funciones posteriores. El ancho y alto corresponden a la mitad de la resolución original de las imagenes del conjunto de datos, pues debido a limitaciones de Hardware no se pudieron procesar en su tamaño original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ancho = 160\n",
    "alto = 129\n",
    "canales = 3\n",
    "pixeles = ancho*alto*canales\n",
    "cantidadClases = 5\n",
    "clases = ['Banano', 'Granada', 'Kiwi', 'Mango', 'Pitaya']\n",
    "batchSize = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos el conjunto de datos de entrenamiento y de prueba, el cuál se llama Fruit Recognition y se puede encontrar en el siguiente enlace: https://www.kaggle.com/datasets/chrisfilo/fruit-recognition\n",
    "\n",
    "El conjunto de datos se modifica para este ejercicio. Originalmente contiene 44.406 imágenes a color de 320×258 pixels, clasificadas en 25 clases. Para este proyecto se seleccionaron 5 clases: Banano, Granada, Kiwi, Mango y Pitaya; Para cada clase se seleccionaron 1500 imágenes para el entrenamiento y 500 imágenes para las pruebas, obteniendo en total 7500 imágenes de entenamiento y 2500 de prueba.\n",
    "\n",
    "Durante la importación se define el atributo barajar (shuffle) como verdadero, esto permite que las imágenes sean cargadas en un orden aleatorio para que el modelo no tome en cuneta el orden de los datos en sus predicciones.\n",
    "\n",
    "Además, se realiza la normalización de los valores para que estén centrados en torno a un valor promedio específico, en este caso estarían centrados alrededor de 0 y variarían en un rango aproximado de (−1,1). Esto ayuda a acelerar el entrenamiento, mejorar la convergencia y aumentar la consistencia entre los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((ancho, alto)),transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),])\n",
    "current_dir = os.getcwd()\n",
    "dataset_path = os.path.join(current_dir, 'dataset', 'Frutas', 'Train')\n",
    "trainset = ImageFolder(root=dataset_path, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batchSize, shuffle=True)\n",
    "\n",
    "testset_path = os.path.join(current_dir, 'dataset', 'Frutas', 'Test')\n",
    "testset = ImageFolder(root=testset_path, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=batchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la función view_classify, que nos permitirá graficar la probabilidad de las clases para nuestras predicciones. Esta función es una modificación de la función que se encuentra en el archivo helper.py del repositorio guía https://github.com/udacity/deep-learning-v2-pytorch/tree/master/intro-to-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_classify(img, ps):\n",
    "  ps = ps.data.numpy().squeeze()\n",
    "  fig, (ax1, ax2) = plt.subplots(figsize=(16,13), ncols=2)\n",
    "  ax1.imshow(img.numpy().transpose((1, 2, 0)))\n",
    "  ax1.axis('off')\n",
    "  ax2.barh(np.arange(cantidadClases), ps)\n",
    "  ax2.set_aspect(0.1)\n",
    "  ax2.set_yticks(np.arange(cantidadClases))\n",
    "  ax2.set_yticklabels(clases, size='medium');\n",
    "  ax2.set_title('Probabilidad de las Clases')\n",
    "  ax2.set_xlim(0, 1.1)\n",
    "\n",
    "  plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper: https://doi.org/10.3390/electronics12143132"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
